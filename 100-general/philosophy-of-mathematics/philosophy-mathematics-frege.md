# General :: Philosophy of mathematics :: Frege

https://en.wikipedia.org/wiki/Edmund_Husserl#Philosophy_of_arithmetic_and_Frege
https://en.wikipedia.org/wiki/Analytic_philosophy
https://en.wikipedia.org/wiki/Philosophy_of_logic#Logical_and_non-logical_formal_systems

## Subject anf methadology of mathematics

youtube.com/watch?v=ucPhfzCvKnE&list=PLhP9EhPApKE-wpP8PtVykRvAjNbYiGhij&index=7

Quantum mechanics is an example of a theory that is successful in making correct predictions, but its interpretation is still vague. It is well understood how the theory is to be employed, but not what it means and what it tells us about the nature of reality.

Mathematics generates a number of questions causing the same kind of puzzlement and has fascinated philosophers from Plato onwards, for two reasons in particular.

*First, it is difficult to precisely say what its subject matter is*. It is reasonably clear what physics or biology investigates, but what exactly is it that mathematics investigates. The standard answer, corresponding to the old-fashioned division of mathematics into arithmetic and geometry, used to be that it investigates quantity and space, but this answer no longer suffice with modern mathematics.

*Second, it is difficult to describe the manner in which mathematicians go about their work*. Unlike other scientists, mathematicians make no observations and have no need for instruments. Instead, they use *logical reasoning* to carry out their work.

The question of what mathematics is about must be answered in a way that agrees with the manner in which it is performed. Whatever mathematics is about, it must be something that can be explored by reasoning alone.

## Necessary truth and a priori knowledge

Philosophy resembles mathematics in this aspect. Philosophers also make no observations and require no instruments. Insofar as these disciplines can be said to involve experiments, these are thought experiments - to imagine an experiment is as good as to actually perform it. The two subjects thus appear to be **a priori** - their results do not require us to observe how the world is, but can be comprehended just by reasoning. They are independent of the world, no matter how the world happens to be. Therefore, they are not merely true, but **necessarily true**, i.e. they are true in all possible worlds (using Kripkean notion of multiple worlds).

Yet philosophy and mathematics differ in all other respects. It is a puzzle how there can be even one subject that can be investigated a priori, let alone two, and so different from one another at that.

A priori knowledge and necessary truth are topics that engage the attention of all philosophers. On the other hand, it seems straightforward to understand how there can be *contingent truths* - things that are so, but might have been different. We get to know contingent truths only a posteriori, either by observation or by deducing from what we already know. But how did it come about that there should also be necessary truth - truth that we can know independently of our experience of the world? How is it that if we knew all contingent truths there would be some truths left over?

It is easy enough to understand trivial necessary truths, such as that there are 7 days in a week or that every widow was once married. To recognize statements of this sort as true, we need know nothing other than the meanings of the words. Moreover, we couldn't claim to know the meanings of the words if we fail to perceive that the statements are true. But mathematical theorems are seldom trivial in this sense. We may not need to start with any initial knowledge, other than the meanings of the words, if we are to come to recognize them as true, but the converse certainly doesn't appear to hold. We may surely know the meanings of the words without realizing that a theorem is true.

Mathematics presents itself as by far the most capacious repository of non-trivial necessary truths, and the knowledge of it is by far the most extensive body of a priori knowledge. This fact alone suffice to make it of intense interest to philosophers.

Admittedly certain philosophers, of whom John Stuart Mill is the best known example, have challenged the a priori character of mathematics claiming that mathematical theories rest upon certain, highly general, contingent facts recognizable by general observation. But this challenge does not alter the situation greatly. At most, empiricists can argue that the starting point of some mathematical theory - the axioms of the theory - is a collection of readily observable contingent facts. They cannot explain why mathematicians don't gather facts by devising experiments or by making observations, like other scientists do. Why instead they content themselves with the meager supply of contingent facts, from which they allegedly begin and proceed to draw out conclusions by means of ever lengthening chains of deductive arguments.

Mathematics is still a science quite unlike any other. The only upshot of the empiricist's contention is what is sometimes called *if-then-ism*, in which necessary truth is restricted by the acceptance of the axioms. That is, 
> if you accept the axioms of some theory, than the exposition that follows is guaranteed to hold.

This leaves the problem of necessary truth untouched. That there should be such an a priori science like philosophy is comparatively intelligible because one of its tasks is to disentangle and explain concepts. Philosophy is not so much about discovering new concepts as it is about better defining of the existing ones. Precise definions also play a critical role in mathematics. Coming up with the correct definition of continuity or dimension was a step of the highest importance. Nevertheless, hitting upon the correct definition of a concept, though often an essential contribution to progress, remains a preliminary to the discovery of mathematical truths, not a means of discovering them; it is not a characteristic activity of mathematicians.

The existence of mathematics is a greater challenge to philosophers to explain than that of philosophy itself. The capacity to wonder is a prerequisite for the activity of philosophizing and anyone who retains this capacity must marvel at the vastness of the body of a priori knowledge amassed by mathematicians only by means of *pure deductive reasoning*.

## Frege

Frege was determined to rectify the situation that greatly distressed him - the inability of either mathematicians or philosophers to explain the basis of our acceptance of mathematical theories. Frege wanted to show what justified our belief in mathematical theories, with what right we assumed the theories to be correct, and their theorems to be true. His first step in carrying out this task was to invent modern mathematical logic.

Kant have maintained the a priori character of mathematics, but to distinguish two varieties of a priori truths - the analytic and the synthetic - *analytic truths* were those guaranteed by logic alone and in Kant's view they were all trivial. They must be recognized immediately by anyone who understood the words in which they were expressed and hence they could not extend our knowledge.

By contrast, the truths of mathematics were *synthetic truths* and hence substantial. The recognition of geometrical truths depended on our intuition of space and the various metrical truths on our intuition of time. Our mathematical knowledge was nevertheless a priori because Kant held that we possess conceptions of space and time independently of any particular experience of our priori intuitions.

Frege accepted Kant's view of our a priori intuition of space, and with it, Kant's view of geometry. He thought that while non-euclidean geometries are logically consistent and thus intelligible, we know a priori that geometry of physical space is Euclidean. But Frege opposed the Kantian view of arithmetic, believing that neither temporal nor spatial intuition played any essential role in our recognition of its truths.

Frege considered the process of mathematical proof must be subjected to scrutiny.

Do we know that all principles of proof, we use in number theory or that we need in order to establish the basic number-theoretic propositions that we frequently take for granted, are of a purely logical character? As long as we reason without paying conscious attention to the steps we take in reasoning, we do not.

We may then mistake for logical transitions ones which in fact rely upon intuition. Conversely, we may suppose an appeal to intuition to be demanded by what can actually be accomplished by purely logical deduction.

It was therefore necessary in Frege's view to attain an explicit systematization of the process of mathematical proof, which he did in the `Begriffsschrift` in 1879. It was a completely original work that did not build on the recent advances in logic by Boole and his successors, that only managed to extended the scope of logic by a small degree beyond what Aristotle had achieved, advancing it to be able to encode arguments that fell within the scope of their theories. But Frege desired something different - a language in which mathematical theorems could be expressed and their proofs carried out in accordance with strictly formal principles of inference.

It is with hindsight astonishing that despite the millennia long study, logic was still incapable of analyzing even the simplest piece of mathematical reasoning. Until Frege, that is, who managed to rectify this. Using a notation quite different from, but isomorphic to, the modern notation, parts one and two of `Begriffsschrift` presented a complete formalization of what is now called *first-order logic*. The part three explored the realm of *second-order logic*, which is the logic governing statements that generalize not only over objects, like the natural numbers, but also over the properties of and relations between these objects.

...

ASIDE (from the current source): Frege's academic career started at the height of this process of axiomatization and rigorization of amthematics, and he contributed to the project in two separate ways. The first contribution, published in 1879, `Begriffsschrift`, concerns the reasoning that takes us from axioms to theorems.

Until Frege, mathematical reasoning was largely informal and conducted in a natural language (often German or French), augmented with mathematical symbols. Frege found this informality unacceptable: "Even if our axioms are purely analytic, how do we know that our proofs haven't tacitly relied on intuitive principles, thus compromising the purity of our theorems and misleading us about the range of their validity? So that nothing intuitive could intrude here unnoticed, everything had to depend on the chain of inferences being free of gaps". Frege found it impossible to enforce this requirement in an informal natural language, so he invented the first ever formal language, his `Begriffsschrift` or "conceptual writing". Frege laid down precise logical axioms and inference rules, which take us from axioms, or theorems already established, to further theorems. In short, Frege's aim of gap-free proofs led him to formulate what is now known as a **formal system**, which is an artificial language with clearly formulated axioms and inference rules, all described with mathematical precision (However unlike the later formalists, Frege took this language to be meaningful, i.e. there was semantics involved, it was not a purely syntactical language). This was arguably the greatest contribution to the axiomatic method since Euclid.

The logic that Frege articulated is far stronger than the broadly Aristotelian logic used by Kant. Frege identified and laid down logical principles governing all the truth-functional connectives and the quantifiers. In fact, Frege recognized several different kinds of quantifiers, which effect different kinds of generalization. *First-order quantifiers* generalize into the position occupied by a singular term or proper name, while the *second-order quantifiers* generalize into the position occupied by a predicate.

Consider, for example, the claim that Socrates, `s`, is mortal, `M`, symbolized as `M(s)`. The first-order logic allows us to state that there is a person `x` such that `x` is mortal, `M(x)`, put together as `∃x(Mx)`. The second-order logic allows us to express the fact that there is a predicate, or a "concept" as Frege put it, `P`, under which Socrates falls (but the predicate is not named here - it could be any predicate, not just mortality), all together expressed as `∃P(P(s))`. (This is the modern logical notation; Frege used a different, but isomorphic, more cumbersome 2D notation).



---



(...elided part of the orginal article...)

Kant couldn't regard mathematical truths as analytic since on the face of it, mathematics massively extends our knowledge. Frege, having decided that arithmetical truths are logical in character and therefore analytic, was faced with explaining how it is that analytic truth can extend our knowledge. This is the same problem as to how deductive reasoning can lead to new knowledge.

For deductive reasoning to be valid, a single inferential step must be both recognizable and compelling. Anyone, who understands the statements figuring as premises and conclusion, must thereby acknowledge that the truth of the former requires acceptance of the latter. But if this is so how can a sequence of such steps take you any distance from where you started?

...

What is problematic is how the existence of *logical objects* can be justified. Logical objects form a special class of abstract objects called by Frege *non-actual objects* because they don't act on other objects or bring about effects in them like physical objects do, and are therefore not perceptible by the senses. His account of what we do when we refer to non-actual objects was based on his celebrated *context principle*.

This principle says that it's only in the context of a sentence that we can refer to anything. Otherwise expressed, we can't mention anything without saying (save as part of a process of saying) something about it. This principle is the most profound, the most difficult, and the most contentious ingredient in all of Frege's philosophy.

Philosophers who deny the existence of *abstract objects* are labeled *nominalists*. They usually characterize abstract objects precisely by them being incapable to ineract with other objects, that is, by their lack of causal powers. The standard nominalist argument against their existence is that since they cannot affect anything, everything must appear exactly the same as if they don't exist. Hence, we have no reason to suppose they exist. Frege cited the term "equator" as an example of such object. It is only when we know how sentences mentioning an abstract object are used, we thereby know what it is to refer to such object.

To justify the use of abstract terms of any given kind in the light of the context principle, we must be able to do what the principle demands. That is, to explain, without circularity, the use of sentences containing such terms and the conditions of their truth and falsity.

Frege require that numbers be recognized as objects so that they can be used to make a statement like "pi is transcendental". And this claim should be treated as being of the same form as the statement "Clinton is unsuccessful". His primary reason was to guarantee the existence of sufficiently many elements of each theory for all possible applications of it, while preserving the purity of arithmetic.

It is easy to imitate Frege's constructions at a higher level. For example, take cardinal numbers as properties of properties of objects, so they are no longer themselves construed as objects. That's essentially what Russell and Whitehead did in Principia, taking properties, for this purpose, extensionally.

The drawback of doing so was that one cannot guarantee anymore that there are infinitely many natural numbers. The solution adopted in Principia was to assume an additional axiom stating that there are infinitely many individuals. This proposition was certainly not a logical truth and was dubious at best, and so the entire project of deriving arithmetic from logic, called *logicism*, was abandoned.

It was by taking numbers to be objects that Frege was able to circumvent this problem. He insisted on the generality of the notion of cardinal numbers - objects of all kinds can be counted - and among things that can be counted are numbers themselves.

When we speak, for example, of prime numbers that are less than or equal to a given number. Likewise, numbers must be objects since a cardinal number is always the odd number of objects satisfying some given condition. This allowed Frege to prove the existence of infinitely many natural numbers independently of the existence of objects of any other kind.

We can show a number `n` to exist by producing a predicate true of just `n` objects. So, the number 0 exists, since "is different from itself" is true of 0 objects. So, "is the number 0" is true of just 1 object. Hence, the number 1 exists. And "is the term of the sequence `0, 1`" is therefore true of just 2 objects, and so the number 2 also exists. In general, given the existence of the numbers from 0 to `n`, the number `n+1` must exist since it is the number of terms in that sequence.

This is a just an informal sketch of the theorem which Frege proved rigorously from his assumptions. The assumptions are easily stated: natural numbers were to be treated as cardinal numbers, and the basic notion of the theory of cardinality is that expressed in a natural language by saying that there are just as many objects of one kind as of another.

Frege adopted as a definition of this notion one that is now accepted. Namely, the existence of a relation mapping the objects of the one kind 1-to-1 onto those of the other kind (i.e. a *bijection*, or a *pair of injections*, one in each direction). Frege proved that all the basic principles of number theory could be derived by means of second-order logic from this fundamental equivalence.

If the introduction of terms for cardinal numbers is to be defended by appeal to the context principle, we need to show that we succeeded in specifying the condition for the truth of any sentence containing such terms. Frege discussed whether the fundamental equivalence could itself be regarded as affecting ⟨Whaa? Being affected by the Russell's paradox or what?⟩. Frege's own answer was negative, so he reformulated his definition in terms of classes: the number of objects of a given kind is the class of classes `A` such that [there are] just as many objects of that kind as members of `A`. The only time Frege used this definition was to derive the fundamental equivalence from it. Its purpose was to introduce terms for numbers in a way he considered unexceptionable.

Frege's ground for denying that the fundamental equivalence served to do what the context principle required was that it failed to determine the condition for the truth or falsity of a statement of identity between a number and an object denoted by a term - not given as a number, not formed by means of the operator - the number of objects. His objection is sound but he overlooked a far more basic one - namely, that the fundamental equivalence does not even determine the truth or falsity of every statement of identity between numbers. It doesn't, for instance, give us any means of deciding whether the number of natural numbers is or is not the same as the number of all cardinal numbers (or of all objects whatsoever).

https://youtu.be/ucPhfzCvKnE?list=TLPQMTEwNTIwMjNxr8Ffg9FzhQ&t=2899
