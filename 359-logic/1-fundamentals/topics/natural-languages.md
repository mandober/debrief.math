# Logic :: About :: Natural languages


Argument, premises and conclusion are just labels that help us discuss logical reasoning, but now we must identify arguments in a natural language, the parts of a natural language that reflect these labels. Whether the argumentation happens in the mind or in verbal or writen communication, it can be modeled the same way - using sentences of a natural language.



Teaching computers to undestand a natural language like English is difficult (but not impossible, see advances with GPT series and similar algorithms), most of all, because all natural languages are ambiguous. Without rephrasing a sentence, it is sometimes impossible to remove *ambiguity*.

Instead, having a small *formal symbolic language* removes ambiguity and decreases an enourmous amount of complexity. However, any one such language seems insufficient to express all that we'd like, even when we constrain ourselves only to the aspects of reasoning, which the large number of types of logic and associated symbolic languages suggests.

Leaving aside computers, we return to the Leibniz vision of a *universal language* using which people would be able to resolve their disagreements. Remaining with the realm of natural languages, we should start with an exploration of the English language from the logical point of view.

In *English*, as in any natural language, the only kinds of sentences of interest to logic are the *declarative sentences* because only such sentences can be assigned a *truth value*. In other words, we cannot discuss whether an interrogative sentence is true, but we can debate the veracity of declarative sentences; we can analyse them and present our arguments as to why we think it is true.


An example of a declarative sentence is "All men are mortal" - we can discuss whether this statement is true or not. That is, this statement can be assigned a truth value, which in classical logic means that it can either be true or false, not both nor neither.


Actually, not even all declarative sentences are suitable for such analysis - statements that talk about future events or statements open to interpretations (among other problematic instances) fall hard on the stomachs of logicians that hold that the principle of bivalence applies to all declarative sentences.

## Argument

In a natural language, we first recognize declarative sentences and then we categorize them according to their *connectives*, which are the *marker words and phrases* such as: and, or, ifâ€¦then, however, thus, so, hence, etc.

An **argument** is made up of *premises* followed by a *conclusion*. In general, words like 'therefore', 'so', 'hence' and 'thus' usually signal that a conclusion is about to be stated, while words like 'because', 'since' and 'for' usually signal premises. Ordinarily, however, things are not always as obvious. Arguments in daily life are frequently rather messy, disordered affairs. Conclusions are sometimes stated before their premises, and identifying which sentences are premises and which sentence is the conclusion can take a little careful thought. However, the real problem for the logician is just how to tell whether or not the conclusion really does follow from the premises. In other words, when is the conclusion a *logical consequence* of the premises?



## NL marker words
- conclusions: thus, therefore, etc.

## Translating English to SL and QL
