# Issue with paradoxes

If we agree that set theory is an appealing foundation of mathematics, then all mathematical objects must be defined as sets. The actual, concrete, set theory at the heart of mathematics today is ZFC, and in ZFC everything is indeed a set. Hence, all mathematical objects are sets - either explicitly and provably so, or can, in principle, be defined in terms of sets if someone insisted really, really hard. At least, that's the hope that many mathematicians cherish. The truth is, mathematicians working in many math fields, fields that are sufficiently remote from set theory, do not give a differentiable shit if the objects of their interest could be defined or derived (all the way) from sets. One thing nearly all mathematicians, working in different fields, have in common is that the set representing the interest in their field's foundations is empty. Hell, if they wanted to fuck around defining things in terms of sets they would be working in the foundations of mathematics, or in set theory, or in mathematical logic (and not waste time in pure math thinking they are better then everyone else).

Paradoxes, right. So all the fuss stems from the foundational fear of the *Russell's paradox*. To avoid it, we must jump through a bunch of hoops, making the involved definitions more complicated and edgier. In set theory alone, we are never working unsupervised, from a blank canvas. The canvas is never blank. There is always an ambient set from which we pick objects (all objects are sets). This is the necessary safety net that prevents us from falling pray to the dreaded Russell's paradox.

Unlike computers, people are fortunate enough to be able to think about thinking. People can observe their though process and kill any thread going in circles aimlessly. Computers can also be programmed in a similar manner, with a main control process that observes other processes and intervene when it detects a repeating cyclic patterns that makes no progress. However, implementing this would be prohibitively expensive, so we don't. As a consequence, a process can run in a loop forever, which it would do upon falling pray to the Russell's paradox.
